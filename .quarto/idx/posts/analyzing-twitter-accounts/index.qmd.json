{"title":"Analyzing Twitter Accounts","markdown":{"yaml":{"title":"Analyzing Twitter Accounts","description":"I grouped Twitter accounts by popularity measure, a quick and easy way to quantify the popularity of a Twitter account","author":"Howard Baek","date":"2019-01-04","categories":["Data Analysis"],"image":"thumbnail.jpg"},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n\nMotivated by [#tidytuesday](https://github.com/rfordatascience/tidytuesday), I will be working with the entire trove of [#rstats tweets](https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-01-01) from its inception on September 7th, 2008 to the most recent one on December 12th, 2018.\n\nThis [tweet](https://twitter.com/robert_squared/status/1080526950245060608) inspired me to use K-Means Clustering, an unsupervised learning method I know a little about, but would like to learn more. I grouped twitter accounts by popularity measure, a quick and easy way (I came up with it) to quantify the popularity of a Twitter account:\n\n> Popularity Measure = Likes + Rewteets + Number of Followers\n\n## Analysis\n\nTo start off, I filtered only for #rstats tweets in 2018, tweets by accounts with more than 400 followers, and selected the following columns: `screen_name`, `favorite_count`(Likes), `retweet_count`, `followers_count`. Hence, I have `rstats_reduced.csv`\n\nFirst, I load packages and import my dataset:\n\n```{r, warning = FALSE, message=FALSE}\nlibrary(tidyverse)\nlibrary(cluster) # For Silhouette Method\nlibrary(broom)\nlibrary(plotly) # For Interactive Visualization\ntheme_set(theme_light()) # Set default theme\n\nrstats <- read_csv(\"rstats_reduced.csv\")\n```\n\nFor the rest of this article, I follow a clear [tutorial](https://uc-r.github.io/kmeans_clustering) in the UC Business Analytics R Programming Guide by [Bradley Boehmke](https://twitter.com/bradleyboehmke).\n\n1.  Make rows as observations and columns as variables\n\n```{r}\n# Find the mean of Likes and Retweets\nrstats_clustering <- rstats %>% \n  group_by(screen_name) %>% \n  mutate(favorite_count_avg = mean(favorite_count),\n         retweet_count_avg = mean(retweet_count)) %>% \n  filter(row_number() == 1) %>% \n  select(screen_name, followers_count, favorite_count_avg, retweet_count_avg) %>% \n  filter(favorite_count_avg <= 20, retweet_count_avg <= 20)\n```\n\n2.  Check for missing values\n\nNone of these columns have NA values, so I don't need to worry about removing or estimating missing values.\n\n3.  Scaling the data (`scale` turns our dataset into a matrix)\n\n```{r, warning=FALSE, message=FALSE}\nrstats_clustering <- rstats_clustering %>% \n  as_data_frame() %>% \n  remove_rownames() %>% \n  column_to_rownames(var = \"screen_name\") %>% \n  scale()\n```\n\nNow, I am done with data preparation and are ready to run the K-Means Algorithm... Not so fast. I need to determine the optimal number of clusters beforehand.\n\nElbow & Silhouette Method (Code borrowed from [DataCamp class: \"Cluster Analysis in R\"](https://www.datacamp.com/courses/cluster-analysis-in-r))\n\n```{r}\n# Set seed\nset.seed(42)\n\n# Use map_dbl to run many models with varying value of k (centers)\nrstats_tot_withinss <- map_dbl(1:10,  function(k){\n  rstats_kmeans <- kmeans(rstats_clustering, centers = k)\n  rstats_kmeans$tot.withinss\n})\n\n# Generate a data frame containing both k and tot_withinss\nelbow_df <- data.frame(\n  k = 1:10 ,\n  tot_withinss = rstats_tot_withinss\n)\n\n# Plot elbow plot\nggplot(elbow_df, aes(x = k, y = tot_withinss)) +\n  geom_line() +\n  scale_x_continuous(breaks = 1:10) +\n  labs(x = \"K\",\n       y = \"Total within-cluster sum of squares\") +\n  ggtitle(\"Elbow Method\",\n          subtitle = \"Since there is no definite elbow, let's use Silhouette Method\")\n```\n\nSilhouette Method\n\n```{r}\n# Use map_dbl to run many models with varying value of k (centers)\nsil_width <- map_dbl(2:10,  function(k){\n  rstats_clustering_model <- pam(x = rstats_clustering, k = k)\n  rstats_clustering_model$silinfo$avg.width\n})\n\nsil_df <- data.frame(\n  k = 2:10,\n  sil_width = sil_width\n)\n\nggplot(sil_df, aes(x = k, y = sil_width)) +\n  geom_line() +\n  scale_x_continuous(breaks = 2:10) +\n  labs(x = \"K\",\n       y = \"Average Silhouette Widths\") +\n  ggtitle(\"Optimal Number of Clusters\",\n          subtitle = \"K = 2 has the highest Silhouette Score\")\n```\n\nFinally, let's run the K-Means Algorithm with K = 2.\n\n```{r}\nrstats_clustering_kmeans <- kmeans(rstats_clustering,\n                                   centers = 2,\n                                   nstart = 25)\n```\n\nNow let's visualize our clustering analysis using a scatterplot of Retweets vs Likes with points colored by cluster. The `plotly` package allows users to hover over each point and view the underlying data. Let's show the Twitter handle, average likes, average retweets and cluster assignments in this `plotly` graph.\n\n```{r}\nclustering_plot <- rstats_clustering %>% \n  as_tibble() %>% \n  mutate(cluster = rstats_clustering_kmeans$cluster,\n         screen_name = rownames(rstats_clustering)) %>% \n  ggplot(aes(x = favorite_count_avg,\n             y = retweet_count_avg,\n             color = factor(cluster),\n             text = paste('Twitter Handle: ', screen_name,\n                  '<br>Average Likes:', round(favorite_count_avg, 1), \n                  '<br>Average Retweets:', round(retweet_count_avg, 1),\n                  '<br>Cluster:', cluster))) +\n  geom_point(alpha = 0.3) +\n  labs(x = \"Average Likes\",\n       y = \"Average Retweets\",\n       color = \"Cluster\"\n       ) +\n  ggtitle(\"K-Means (K=2) Clustering of Twitter Screen Names\")\n  \nggplotly(clustering_plot, tooltip = \"text\")\n```\n\n<br>\n\n## Conclusion\n\nIn this article, I imported the #rstats tweets dataset, prepared it for cluster analysis, determined the optimal number of clusters, and visualized those clusters with `plotly`. The interactive graph clearly shows two distinct clusters of twitter accounts according to average retweets, average likes, and number of followers.\n\nEven though the K-Means algorithm isn't a perfect algorithm, it can be very useful for **exploratory data analysis**. It divides twitter accounts into two groups according to my \"popularity measure\" and allows for further analysis one group (Cluster 1 or Cluster 2) at a time.\n\nThank you for reading!\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"output-file":"index.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.335","editor":"visual","theme":"litera","title-block-banner":true,"comments":{"utterances":{"repo":"howardbaek/blog-comments"}},"title":"Analyzing Twitter Accounts","description":"I grouped Twitter accounts by popularity measure, a quick and easy way to quantify the popularity of a Twitter account","author":"Howard Baek","date":"2019-01-04","categories":["Data Analysis"],"image":"thumbnail.jpg"},"extensions":{"book":{"multiFile":true}}}}}